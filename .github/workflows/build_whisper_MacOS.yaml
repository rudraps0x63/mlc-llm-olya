name: Compile Whisper-Tiny for MacOS (with Metal)

on:
  workflow_dispatch:
    inputs:
      quantization:
        description: "Choose quantization for model"
        required: true
        default: "q0f32"
        type: choice
        options:
          - q0f32
          - q4f32_1

jobs:
  build-macos:
    runs-on: macos-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          submodules: 'recursive'

      - name: Install Dependencies
        run: |
          brew install llvm cmake git python@3.11 git-lfs
          python3.11 -m venv ./venv
          source ./venv/bin/activate
          python3.11 -m pip install --upgrade pip
          export PATH="/opt/homebrew/opt/llvm/bin:$PATH"

      - name: Clone and Build TVM with Metal
        run: |
          export PATH="/opt/homebrew/opt/llvm/bin:$PATH"
          source ./venv/bin/activate
          cd ..
          git clone --recursive https://github.com/apache/tvm tvm_
          echo "TVM_HOME=$(pwd)/tvm_" >> $GITHUB_ENV
          cd tvm_
          git reset --hard d5b9f5c30bc3e1f5e1a283ed19c5440afcc45889
          mkdir build
          cd build
          cp ../cmake/config.cmake .
          echo "set(CMAKE_BUILD_TYPE Release)" >> config.cmake
          echo "set(USE_LLVM \"llvm-config --ignore-libllvm --link-static\")" >> config.cmake
          echo "set(HIDE_PRIVATE_SYMBOLS OFF)" >> config.cmake
          echo "set(USE_METAL ON)" >> config.cmake
          cmake ..
          cmake --build . --parallel $(sysctl -n hw.ncpu)
          cd ..
          cd python
          pip install -e .
     
      - name: Build the repository
        shell: bash
        run: |
          source ./venv/bin/activate
          mkdir build
          cd build
          cp ../cmake/config.cmake .
          echo "set(TVM_SOURCE_DIR ${{ env.TVM_HOME }})" >> config.cmake
          echo "set(USE_METAL ON)" >> config.cmake
          cat config.cmake
          cmake ..
          cmake --build . --parallel $(sysctl -n hw.ncpu)

      - name: Download model
        run: |
          git-lfs install
          cd python
          git clone --depth 1 https://huggingface.co/openai/whisper-tiny

      - name: Install the built MLC-LLM package
        run: |
          source ./venv/bin/activate
          cd python
          pip install -e .

      - uses: mxschmitt/action-tmate@v3

      - name: Compile model
        run: |
          source ./venv/bin/activate

      - name: Upload compiled model as artifact
        uses: actions/upload-artifact@v3
        with:
          name: output-${{ github.event.inputs.quantization }}-opus-mt-${{ github.event.inputs.language_pair }}
          path: output-${{ github.event.inputs.quantization }}-opus-mt-${{ github.event.inputs.language_pair }}/
