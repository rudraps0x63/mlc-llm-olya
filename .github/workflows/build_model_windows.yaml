# GH actions.
# We use it to cover windows builds
# Jenkins is still the primary CI
name: Compile Whisper for Windows (x64 with Vulkan)

on:
  workflow_dispatch:
    inputs:
      quantization:
        description: "Choose quantization for model"
        required: true
        default: "q0f32"
        type: choice
        options:
          - q0f32
          - q4f32_1

jobs:
  Build-Marian-Windows:
    runs-on: windows-latest
    defaults:
      run:
        shell: 'cmd /C call {0}'

    steps:
    - name: Git config
      run: >-
        git config --system core.longpaths true
    - uses: actions/checkout@v3
      with:
        submodules: 'recursive'

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Create venv
      run: |
        python -m venv mlc_build_env
        call .\mlc_build_env\Scripts\activate
        python --version

    - name: Install winget
      uses: Cyberboss/install-winget@v1

    - name: Install dependencies
      run: |
        winget install -e --id KhronosGroup.VulkanSDK --accept-source-agreements --accept-package-agreements

    - name: Install Visual Studio Build Tools 2022
      run: |
        choco install visualstudio2022buildtools --version=17.11.9
        refreshenv
        python -v -c "import ssl; print(ssl.__file__)"

    - name: Build MLC-LLM
      shell: pwsh
      run: |
        $buildDir = pwd
        cd C:\VulkanSDK\*
        $env:VULKAN_SDK = pwd
        cd $buildDir
        call .\mlc_build_env\Scripts\activate
        mkdir build
        cd build 
        cmake -DUSE_VULKAN=ON ..
        cmake --build . --parallel 16 --config Release
        python -v -c "import ssl; print(ssl.__file__)"

    - uses: mxschmitt/action-tmate@v3

    - name: Install mlc-llm
      run: |
        call .\mlc_build_env\Scripts\activate
        set "PATH=%PATH%;D:\a\mlc-llm\tvm\build\Debug;D:\a\mlc-llm\mlc-llm\build\tokenizers\sentencepiece\src\Debug;D:\a\mlc-llm\mlc-llm\build\tokenizers\Debug;D:\a\mlc-llm\mlc-llm\build\Debug"
        cd python
        pip install -e .
        python -v -c "import ssl; print(ssl.__file__)"
        python -v -c "import os; print(os.environ.get('PATH')); import mlc_llm; print(mlc_llm.__file__)"

    - name: download the model
      run: |
        git clone https://huggingface.co/openai/whisper-tiny

    - name: Compile model
      run: |
        call .\mlc_build_env\Scripts\activate
        python -v -c "import ssl; print(ssl.__file__)"
        python -v -c "import mlc_llm; print(mlc_llm.__file__)"
        #set "PATH=%PATH%;D:\a\mlc-llm\tvm\build\Debug;D:\a\mlc-llm\mlc-llm\build\tokenizers\sentencepiece\src\Debug;D:\a\mlc-llm\mlc-llm\build\tokenizers\Debug;D:\a\mlc-llm\mlc-llm\build\Debug;"
        python -m mlc_llm convert_weight --model-type marian ./opus-mt-en-it --quantization q0f32 --output ./output
        #ci/models_build/marian.bat "${{ github.event.inputs.quantization }}" "${{ github.event.inputs.language_pair }}"
    
    - name: Upload compied model as artifact
      uses: actions/upload-artifact@v3
      with:
          name: output-${{ github.event.inputs.quantization }}-opus-mt-${{ github.event.inputs.language_pair }}
          path: output-${{ github.event.inputs.quantization }}-opus-mt-${{ github.event.inputs.language_pair }}/
            

